pip install streamlit torch torchvision pillow opencv-python
import io
import numpy as np
import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as T
from torchvision import models
import cv2

st.set_page_config(page_title="ë™ë¬¼ ë¶„ë¥˜ & ì–¼êµ´ íƒì§€", page_icon="ğŸ¾", layout="wide")
st.title("ğŸ¾ ë™ë¬¼ ë¶„ë¥˜ & ğŸ™‚ ì–¼êµ´ íƒì§€ (ì‹ ì› ì‹ë³„ ì—†ìŒ)")

# -----------------------------
# ìºì‹œëœ ëª¨ë¸ ë¡œë”
# -----------------------------
@st.cache_resource
def load_imagenet_model():
    weights = models.ResNet50_Weights.DEFAULT  # ImageNet1K
    model = models.resnet50(weights=weights)
    model.eval()
    preprocess = weights.transforms()
    categories = weights.meta["categories"]
    return model, preprocess, categories

# -----------------------------
# ìœ í‹¸: PIL ì´ë¯¸ì§€ â†’ torch í…ì„œ ì „ì²˜ë¦¬
# -----------------------------
def prepare_image(pil_img, preprocess):
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    return preprocess(pil_img).unsqueeze(0)

# -----------------------------
# ì˜ˆì¸¡ í•¨ìˆ˜ (Top-k)
# -----------------------------
@torch.inference_mode()
def predict_topk(pil_img, model, preprocess, categories, k=5):
    inp = prepare_image(pil_img, preprocess)
    logits = model(inp)
    probs = torch.softmax(logits, dim=1)[0]
    topk = torch.topk(probs, k)
    results = []
    for score, idx in zip(topk.values.tolist(), topk.indices.tolist()):
        results.append((categories[idx], float(score)))
    return results

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2 = st.tabs(["ğŸ¦ ë™ë¬¼ ë¶„ë¥˜", "ğŸ™‚ ì–¼êµ´ íƒì§€(ì‹ ì› ì‹ë³„ ì—†ìŒ)"])

# -----------------------------
# íƒ­1: ë™ë¬¼ ë¶„ë¥˜
# -----------------------------
with tab1:
    st.subheader("ì´ë¯¸ì§€ ì† ë™ë¬¼(ë˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ í´ë˜ìŠ¤) ì˜ˆì¸¡")
    st.caption("ImageNet ì‚¬ì „í•™ìŠµ ëª¨ë¸(ResNet50)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë™ë¬¼ ì™¸ ì‚¬ë¬¼ë¡œ ì˜ˆì¸¡ë  ìˆ˜ë„ ìˆì–´ìš”.")
    up1 = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg/png)", type=["jpg", "jpeg", "png"], key="animal")
    if up1 is not None:
        try:
            img = Image.open(io.BytesIO(up1.read()))
            st.image(img, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_column_width=True)
            with st.spinner("ë¶„ì„ ì¤‘..."):
                model, preprocess, categories = load_imagenet_model()
                preds = predict_topk(img, model, preprocess, categories, k=5)

            st.success("ì˜ˆì¸¡ ê²°ê³¼ (Top-5)")
            for i, (label, score) in enumerate(preds, start=1):
                st.write(f"{i}. **{label}** â€” {score*100:.2f}%")
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

# -----------------------------
# íƒ­2: ì–¼êµ´ íƒì§€ (ì‹ ì› ì‹ë³„ ì—†ìŒ)
# -----------------------------
with tab2:
    st.subheader("ì–¼êµ´ ìœ ë¬´/ê°œìˆ˜ íƒì§€ (ì‹ ì› ì‹ë³„ì€ í•˜ì§€ ì•Šì•„ìš”)")
    st.caption("OpenCV Haar Cascadeë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³  ë°•ìŠ¤ë¥¼ ê·¸ë ¤ì¤ë‹ˆë‹¤.")
    up2 = st.file_uploader("ì–¼êµ´ì´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg/png)", type=["jpg", "jpeg", "png"], key="face")
    if up2 is not None:
        try:
            img = Image.open(io.BytesIO(up2.read()))
            if img.mode != "RGB":
                img = img.convert("RGB")

            # PIL â†’ OpenCV BGR
            img_np = np.array(img)
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

            # Haar Cascade ë¡œë“œ
            cascade_path = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            face_cascade = cv2.CascadeClassifier(cascade_path)

            gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))

            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            for (x, y, w, h) in faces:
                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 255, 0), 3)

            # ë‹¤ì‹œ RGBë¡œ ë³€í™˜ í›„ í‘œì‹œ
            out_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            st.image(out_rgb, caption=f"ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {len(faces)}", use_column_width=True)

            if len(faces) == 0:
                st.info("ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

st.markdown("---")
st.caption(
    "ì•ˆë‚´: ì´ ì•±ì€ ì‚¬ì§„ ì† ì¸ë¬¼ì„ ëˆ„êµ¬ì¸ì§€ **ì‹ë³„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**. "
    "ë™ë¬¼ ë¶„ë¥˜ëŠ” ImageNet ê¸°ë°˜ìœ¼ë¡œ ì¶”ì • ê²°ê³¼ë¥¼ ì œê³µí•˜ë©°, ì‚¬ì§„Â·ê°ë„Â·í•´ìƒë„ì— ë”°ë¼ ì •í™•ë„ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)
streamlit run app.py

